{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest regressor for ride duration\n",
    "\n",
    "This notebook creates and logs the model pipeline onto MLflow for the web-service app to retrieve and make predictions on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/27 00:25:51 INFO mlflow.tracking.fluent: Experiment with name 'green-taxi-duration' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow-artifacts-remote-1212/3', experiment_id='3', lifecycle_stage='active', name='green-taxi-duration', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "TRACKING_IP = '13.215.46.159'\n",
    "mlflow.set_tracking_uri(f'http://{TRACKING_IP}:5000')\n",
    "mlflow.set_experiment(\"green-taxi-duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename: str):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.dt.total_seconds() / 60\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_dictionaries(df: pd.DataFrame):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('../../data/green_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('../../data/green_tripdata_2021-02.parquet')\n",
    "\n",
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values\n",
    "\n",
    "dict_train = prepare_dictionaries(df_train)\n",
    "dict_val = prepare_dictionaries(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By combining the dict_vectorizer and model into one, the web service app no longer needs to handle two different objects - just transform and predict with one object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'n_estimators': 100, 'min_samples_leaf': 10, 'random_state': 0} 6.7558229919200725\n"
     ]
    },
    {
     "ename": "S3UploadFailedError",
     "evalue": "Failed to upload /tmp/tmp69l38unl/model/model.pkl to mlflow-artifacts-remote-1212/3/252c01d31b6b4100acfc0e4a03b29207/artifacts/model/model.pkl: An error occurred (InvalidAccessKeyId) when calling the CreateMultipartUpload operation: The AWS Access Key Id you provided does not exist in our records.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/boto3/s3/transfer.py:288\u001b[0m, in \u001b[0;36mS3Transfer.upload_file\u001b[0;34m(self, filename, bucket, key, callback, extra_args)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    289\u001b[0m \u001b[39m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39m# client error.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/s3transfer/futures.py:106\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[39m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[39m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[39m# out of this and propogate the exception.\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coordinator\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    107\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/s3transfer/futures.py:265\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    266\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/s3transfer/tasks.py:126\u001b[0m, in \u001b[0;36mTask.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_coordinator\u001b[39m.\u001b[39mdone():\n\u001b[0;32m--> 126\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_main(kwargs)\n\u001b[1;32m    127\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/s3transfer/tasks.py:150\u001b[0m, in \u001b[0;36mTask._execute_main\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m logger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    147\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mExecuting task \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m with kwargs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m, kwargs_to_display)\n\u001b[1;32m    148\u001b[0m )\n\u001b[0;32m--> 150\u001b[0m return_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_main(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39m# If the task is the final task, then set the TransferFuture's\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m# value to the return value from main().\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/s3transfer/tasks.py:332\u001b[0m, in \u001b[0;36mCreateMultipartUploadTask._main\u001b[0;34m(self, client, bucket, key, extra_args)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39m# Create the multipart upload.\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mcreate_multipart_upload(\n\u001b[1;32m    333\u001b[0m     Bucket\u001b[39m=\u001b[39;49mbucket, Key\u001b[39m=\u001b[39;49mkey, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_args)\n\u001b[1;32m    334\u001b[0m upload_id \u001b[39m=\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39mUploadId\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/botocore/client.py:401\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/botocore/client.py:731\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    730\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 731\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    732\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (InvalidAccessKeyId) when calling the CreateMultipartUpload operation: The AWS Access Key Id you provided does not exist in our records.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mS3UploadFailedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/klang/mlops-notes/w4-deployment/web-service-mlflow/random-forest.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/klang/mlops-notes/w4-deployment/web-service-mlflow/random-forest.ipynb#ch0000006vscode-remote?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(params, rmse)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/klang/mlops-notes/w4-deployment/web-service-mlflow/random-forest.ipynb#ch0000006vscode-remote?line=15'>16</a>\u001b[0m mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m'\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m'\u001b[39m, rmse)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/klang/mlops-notes/w4-deployment/web-service-mlflow/random-forest.ipynb#ch0000006vscode-remote?line=17'>18</a>\u001b[0m mlflow\u001b[39m.\u001b[39;49msklearn\u001b[39m.\u001b[39;49mlog_model(pipeline, artifact_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/mlflow/sklearn/__init__.py:393\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[39m.\u001b[39mformat(package_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mscikit-learn\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_model\u001b[39m(\n\u001b[1;32m    311\u001b[0m     sk_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    321\u001b[0m     extra_pip_requirements\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    322\u001b[0m ):\n\u001b[1;32m    323\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[39m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39m    containing the following flavors:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39m        mlflow.sklearn.log_model(sk_model, \"sk_models\")\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m     \u001b[39mreturn\u001b[39;00m Model\u001b[39m.\u001b[39;49mlog(\n\u001b[1;32m    394\u001b[0m         artifact_path\u001b[39m=\u001b[39;49martifact_path,\n\u001b[1;32m    395\u001b[0m         flavor\u001b[39m=\u001b[39;49mmlflow\u001b[39m.\u001b[39;49msklearn,\n\u001b[1;32m    396\u001b[0m         sk_model\u001b[39m=\u001b[39;49msk_model,\n\u001b[1;32m    397\u001b[0m         conda_env\u001b[39m=\u001b[39;49mconda_env,\n\u001b[1;32m    398\u001b[0m         code_paths\u001b[39m=\u001b[39;49mcode_paths,\n\u001b[1;32m    399\u001b[0m         serialization_format\u001b[39m=\u001b[39;49mserialization_format,\n\u001b[1;32m    400\u001b[0m         registered_model_name\u001b[39m=\u001b[39;49mregistered_model_name,\n\u001b[1;32m    401\u001b[0m         signature\u001b[39m=\u001b[39;49msignature,\n\u001b[1;32m    402\u001b[0m         input_example\u001b[39m=\u001b[39;49minput_example,\n\u001b[1;32m    403\u001b[0m         await_registration_for\u001b[39m=\u001b[39;49mawait_registration_for,\n\u001b[1;32m    404\u001b[0m         pip_requirements\u001b[39m=\u001b[39;49mpip_requirements,\n\u001b[1;32m    405\u001b[0m         extra_pip_requirements\u001b[39m=\u001b[39;49mextra_pip_requirements,\n\u001b[1;32m    406\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/mlflow/models/model.py:295\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m mlflow_model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(artifact_path\u001b[39m=\u001b[39martifact_path, run_id\u001b[39m=\u001b[39mrun_id)\n\u001b[1;32m    294\u001b[0m flavor\u001b[39m.\u001b[39msave_model(path\u001b[39m=\u001b[39mlocal_path, mlflow_model\u001b[39m=\u001b[39mmlflow_model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 295\u001b[0m mlflow\u001b[39m.\u001b[39;49mtracking\u001b[39m.\u001b[39;49mfluent\u001b[39m.\u001b[39;49mlog_artifacts(local_path, artifact_path)\n\u001b[1;32m    296\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     mlflow\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mfluent\u001b[39m.\u001b[39m_record_logged_model(mlflow_model)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/mlflow/tracking/fluent.py:726\u001b[0m, in \u001b[0;36mlog_artifacts\u001b[0;34m(local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39mLog all the contents of a local directory as artifacts of the run. If no run is active,\u001b[39;00m\n\u001b[1;32m    699\u001b[0m \u001b[39mthis method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[39m        mlflow.log_artifacts(\"data\", artifact_path=\"states\")\u001b[39;00m\n\u001b[1;32m    724\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    725\u001b[0m run_id \u001b[39m=\u001b[39m _get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[0;32m--> 726\u001b[0m MlflowClient()\u001b[39m.\u001b[39;49mlog_artifacts(run_id, local_dir, artifact_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/mlflow/tracking/client.py:1001\u001b[0m, in \u001b[0;36mMlflowClient.log_artifacts\u001b[0;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_artifacts\u001b[39m(\n\u001b[1;32m    958\u001b[0m     \u001b[39mself\u001b[39m, run_id: \u001b[39mstr\u001b[39m, local_dir: \u001b[39mstr\u001b[39m, artifact_path: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    959\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    961\u001b[0m \u001b[39m    Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[39m        is_dir: True\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1001\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mlog_artifacts(run_id, local_dir, artifact_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:346\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifacts\u001b[0;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_artifacts\u001b[39m(\u001b[39mself\u001b[39m, run_id, local_dir, artifact_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    340\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[39m    Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \n\u001b[1;32m    343\u001b[0m \u001b[39m    :param local_dir: Path to the directory of files to write.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39m    :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_artifact_repo(run_id)\u001b[39m.\u001b[39;49mlog_artifacts(local_dir, artifact_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/mlflow/store/artifact/s3_artifact_repo.py:141\u001b[0m, in \u001b[0;36mS3ArtifactRepository.log_artifacts\u001b[0;34m(self, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    139\u001b[0m     upload_path \u001b[39m=\u001b[39m posixpath\u001b[39m.\u001b[39mjoin(dest_path, rel_path)\n\u001b[1;32m    140\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m filenames:\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_upload_file(\n\u001b[1;32m    142\u001b[0m         s3_client\u001b[39m=\u001b[39;49ms3_client,\n\u001b[1;32m    143\u001b[0m         local_file\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(root, f),\n\u001b[1;32m    144\u001b[0m         bucket\u001b[39m=\u001b[39;49mbucket,\n\u001b[1;32m    145\u001b[0m         key\u001b[39m=\u001b[39;49mposixpath\u001b[39m.\u001b[39;49mjoin(upload_path, f),\n\u001b[1;32m    146\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/mlflow/store/artifact/s3_artifact_repo.py:117\u001b[0m, in \u001b[0;36mS3ArtifactRepository._upload_file\u001b[0;34m(self, s3_client, local_file, bucket, key)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m environ_extra_args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     extra_args\u001b[39m.\u001b[39mupdate(environ_extra_args)\n\u001b[0;32m--> 117\u001b[0m s3_client\u001b[39m.\u001b[39;49mupload_file(Filename\u001b[39m=\u001b[39;49mlocal_file, Bucket\u001b[39m=\u001b[39;49mbucket, Key\u001b[39m=\u001b[39;49mkey, ExtraArgs\u001b[39m=\u001b[39;49mextra_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/boto3/s3/inject.py:143\u001b[0m, in \u001b[0;36mupload_file\u001b[0;34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m\"\"\"Upload a file to an S3 object.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \n\u001b[1;32m    110\u001b[0m \u001b[39mUsage::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m    transfer.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39mwith\u001b[39;00m S3Transfer(\u001b[39mself\u001b[39m, Config) \u001b[39mas\u001b[39;00m transfer:\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m transfer\u001b[39m.\u001b[39;49mupload_file(\n\u001b[1;32m    144\u001b[0m         filename\u001b[39m=\u001b[39;49mFilename,\n\u001b[1;32m    145\u001b[0m         bucket\u001b[39m=\u001b[39;49mBucket,\n\u001b[1;32m    146\u001b[0m         key\u001b[39m=\u001b[39;49mKey,\n\u001b[1;32m    147\u001b[0m         extra_args\u001b[39m=\u001b[39;49mExtraArgs,\n\u001b[1;32m    148\u001b[0m         callback\u001b[39m=\u001b[39;49mCallback,\n\u001b[1;32m    149\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.9/site-packages/boto3/s3/transfer.py:294\u001b[0m, in \u001b[0;36mS3Transfer.upload_file\u001b[0;34m(self, filename, bucket, key, callback, extra_args)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[39m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39m# client error.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[39mexcept\u001b[39;00m ClientError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 294\u001b[0m     \u001b[39mraise\u001b[39;00m S3UploadFailedError(\n\u001b[1;32m    295\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to upload \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    296\u001b[0m             filename, \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([bucket, key]), e\n\u001b[1;32m    297\u001b[0m         )\n\u001b[1;32m    298\u001b[0m     )\n",
      "\u001b[0;31mS3UploadFailedError\u001b[0m: Failed to upload /tmp/tmp69l38unl/model/model.pkl to mlflow-artifacts-remote-1212/3/252c01d31b6b4100acfc0e4a03b29207/artifacts/model/model.pkl: An error occurred (InvalidAccessKeyId) when calling the CreateMultipartUpload operation: The AWS Access Key Id you provided does not exist in our records."
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    params = dict(max_depth=20, n_estimators=100, min_samples_leaf=10, random_state=0)\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # use pipeline to combine dict_vect and model into one object\n",
    "    pipeline = make_pipeline(\n",
    "        DictVectorizer(),\n",
    "        RandomForestRegressor(**params, n_jobs=-1)\n",
    "    )\n",
    "\n",
    "    pipeline.fit(dict_train, y_train)\n",
    "    y_pred = pipeline.predict(dict_val)\n",
    "\n",
    "    rmse = mean_squared_error(y_pred, y_val, squared=False)\n",
    "    print(params, rmse)\n",
    "    mlflow.log_metric('rmse', rmse)\n",
    "\n",
    "    mlflow.sklearn.log_model(pipeline, artifact_path=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mlops')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "394f3d1284bcc760c8bc7e6eea62ce7967eec8f82d1c3f540f6ead99cec26d91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
