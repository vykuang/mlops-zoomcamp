{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 - Experiment Tracking and Model Registry with MLFlow\n",
    "\n",
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow, version 1.26.0\n"
     ]
    }
   ],
   "source": [
    "!mlflow --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download and preprocess\n",
    "\n",
    "Use green taxi trip records from 2021-01 to 2021-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL format: https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-01.parquet\n",
    "# looking for 2021-01, 02, 03\n",
    "# use requests\n",
    "\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "def download_from_url(url: str, file_dir: str):\n",
    "    \"\"\"Wrapper function for requests library to stream download,\n",
    "    i.e. without needing to store entire file in memory, and allows\n",
    "    download to proceed in chunks\n",
    "\n",
    "    Args:\n",
    "    url: string\n",
    "        direct url to the file for download, e.g.\n",
    "        https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-01.parquet\n",
    "\n",
    "    file_dir: string\n",
    "        path to the download destination directory\n",
    "    \"\"\"\n",
    "    file_dir = Path(file_dir)\n",
    "    if not file_dir:\n",
    "        Path.mkdir(file_dir)\n",
    "\n",
    "    # local_file = url.split('/')[-1].replace(\" \", \"_\")\n",
    "    # use built-in method to extract filename:\n",
    "    local_file = Path(url).name\n",
    "    local_path = Path(file_dir) / local_file\n",
    "\n",
    "    if not local_path.exists():\n",
    "        r = requests.get(url, stream=True)\n",
    "        if r.ok:\n",
    "            print('Saving to ', local_path)\n",
    "            with open(local_path, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=1024*8):\n",
    "                    # if chunk:\n",
    "                    # iter_content will never return None type\n",
    "                    f.write(chunk)\n",
    "                    # f.flush()\n",
    "                    # os.fsync(f.fileno())\n",
    "        else:\n",
    "            # HTTP status 4xx/5xx\n",
    "            print(f'Download failed with code {r.status_code}\\n{r.text}')\n",
    "    else:\n",
    "        print(f'File already exists:\\n{local_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists:\n",
      "/home/klang/mlops-notes/data/green_tripdata_2021-01.parquet\n",
      "File already exists:\n",
      "/home/klang/mlops-notes/data/green_tripdata_2021-02.parquet\n",
      "File already exists:\n",
      "/home/klang/mlops-notes/data/green_tripdata_2021-03.parquet\n"
     ]
    }
   ],
   "source": [
    "# url = 'https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-01.parquet'\n",
    "parquet_urls = [f'https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-{month:02}.parquet'\n",
    "                for month in range(1, 4)] \n",
    "dest_path = Path.cwd().parents[1] / 'data'\n",
    "\n",
    "for url in parquet_urls:\n",
    "    download_from_url(url, dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess\n",
    "\n",
    "Run `preprocess_data.py` and examine the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocess_data.py --raw_data_path ~/mlops-notes/data --dest_path ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/klang/mlops-notes/notebooks/w2-mlflow/output/dv.pkl'),\n",
       " PosixPath('/home/klang/mlops-notes/notebooks/w2-mlflow/output/valid.pkl'),\n",
       " PosixPath('/home/klang/mlops-notes/notebooks/w2-mlflow/output/test.pkl'),\n",
       " PosixPath('/home/klang/mlops-notes/notebooks/w2-mlflow/output/train.pkl')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = Path.cwd() / 'output'\n",
    "list(output_path.glob('*.*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with autolog\n",
    "\n",
    "Use random forest regressor via `train.py`. The script loads the outputs from previous step, trains model on `train.pkl`, and calculates RMSE on `valid.pkl`.\n",
    "\n",
    "Modify so that MLflow's **autolog** is enabled. Launch MLflow UI to confirm tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "394f3d1284bcc760c8bc7e6eea62ce7967eec8f82d1c3f540f6ead99cec26d91"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mlops')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
